---
title: "3.6.2 诊断问题：AI 错在哪里"
---


![03-technique_3.6-debugging-ai_3.6.2-diagnose-problems.png](../../../public/images/Basic/03-technique_3.6-debugging-ai_3.6.2-diagnose-problems.png)
# 3.6.2 诊断问题：AI 错在哪里

## 经过本节学习，你将掌握

- 使用「三分钟快速诊断法」定位问题
- 区分「我没说清楚」和「AI 能力不足」
- 根据问题类型选择正确的应对策略
- 获得一个诊断决策树

## 诊断的核心问题

当 AI 输出不符合预期时，你首先要回答一个问题：

> **是我没说清楚，还是 AI 没做对？**

这个问题的答案，决定了你下一步应该做什么：
- 如果是你没说清楚 → 补充上下文，重新描述
- 如果是 AI 没做对 → 换种问法，或者换个策略

## 三分钟快速诊断法

在深入分析之前，先用这三步快速排查，能捕获约 60% 的常见问题：

### 第一步：运行代码检查（30 秒）

```bash
# 如果是 JavaScript/TypeScript 项目
npx eslint <文件名>   # 检查语法和格式问题
npx tsc --noEmit      # 检查类型错误（如果用 TypeScript）
```

**能发现的问题**：
- 语法错误（少了括号、拼错关键字）
- 类型不匹配
- 未定义的变量

### 第二步：检查依赖和 API（60 秒）

对照代码中的 import 语句，检查：

- <input type="checkbox" name="第二步检查依赖和-api60-秒-checklist" value="引入的包是否存在用-361-中的验证方法" /> <label for="引入的包是否存在用-361-中的验证方法">引入的包是否存在？（用 3.6.1 中的验证方法）</label>
- <input type="checkbox" name="第二步检查依赖和-api60-秒-checklist" value="调用的方法是否真的存在于该包中" /> <label for="调用的方法是否真的存在于该包中">调用的方法是否真的存在于该包中？</label>
- <input type="checkbox" name="第二步检查依赖和-api60-秒-checklist" value="版本是否匹配" /> <label for="版本是否匹配">版本是否匹配？</label>

**能发现的问题**：
- 包幻觉
- API 幻觉
- 版本兼容问题

### 第三步：运行现有测试（90 秒）

如果项目有测试用例：

```bash
npm test           # 或你项目的测试命令
```

**能发现的问题**：
- 行为变更（原来能跑的功能被改坏了）
- 逻辑错误
- 边界情况处理不当

## 根因分析四象限

如果三分钟诊断没有定位到问题，用这个四象限来分析根本原因：

```
                    我说得清楚
                        ↑
          ┌─────────────┼─────────────┐
          │             │             │
          │   AI 出错   │  补充上下文 │
 简单任务 │  → 换问法   │  → 重新描述 │  复杂任务
          │             │             │
          ├─────────────┼─────────────┤
          │             │             │
          │  拆分任务   │ 重描述+拆分 │
          │  → 分步做   │  → 降低复杂度│
          │             │             │
          └─────────────┴─────────────┘
                        ↓
                    我没说清楚
```

### 象限一：简单任务 + 我说得清楚 → AI 出错

**特征**：
- 任务很明确，不应该有歧义
- 你给的信息足够完整
- 但 AI 的输出明显不对

**应对策略**：
- 换一种问法重新描述
- 给出正确示例让 AI 参考
- 尝试不同的 AI 工具

**示例**：
```
原提示词：写一个判断闰年的函数

问题：AI 给的逻辑不对

换种问法：
"请写一个判断闰年的 JavaScript 函数。
闰年规则：
1. 能被 4 整除且不能被 100 整除，是闰年
2. 能被 400 整除，也是闰年
请严格按照这个规则实现。"
```

### 象限二：简单任务 + 我没说清楚 → 补充上下文

**特征**：
- 任务本身不复杂
- 但你假设了 AI 知道某些背景
- AI 按自己的理解做了，和你想的不一样

**应对策略**：
- 补充项目背景
- 明确技术栈和约束
- 说明你期望的输出格式

**示例**：
```
原提示词：写一个表单验证

问题：AI 用了你项目没有的验证库

补充上下文：
"我的项目使用 React + Zod 做表单验证。
请用 Zod 写一个用户注册表单的验证 schema，包括：
- 邮箱格式验证
- 密码至少 8 位
- 确认密码要一致"
```

### 象限三：复杂任务 + 我说得清楚 → 拆分任务

**特征**：
- 任务涉及多个步骤或模块
- 你描述得很清楚
- 但 AI 的输出质量不稳定，有些对有些错

**应对策略**：
- 把大任务拆成小任务
- 一次只让 AI 做一件事
- 分步骤完成后再整合

**示例**：
```
原提示词（太大）：
"实现一个完整的用户认证系统，包括注册、登录、找回密码、JWT 令牌管理"

拆分后：
第一轮："先实现用户注册功能，只需要邮箱和密码"
第二轮："现在加上登录功能，返回 JWT 令牌"
第三轮："加上令牌验证中间件"
第四轮："最后加上找回密码功能"
```

### 象限四：复杂任务 + 我没说清楚 → 重新描述 + 拆分

**特征**：
- 任务复杂
- 你自己可能也没完全想清楚
- AI 的输出和你想的差很远

**应对策略**：
- 先退一步，理清自己的需求
- 用 3.4 节学的 PRD 方法整理思路
- 然后拆分成小任务逐个完成

**示例**：
```
原提示词（模糊又复杂）：
"帮我做一个类似 Notion 的笔记应用"

理清需求后：
"我想做一个个人笔记应用，MVP 版本只需要：
1. 创建/编辑/删除笔记
2. 笔记列表页
3. 本地存储

先帮我实现第一个功能：创建和显示笔记列表。
技术栈：React + localStorage"
```

## 诊断 Prompt：让 AI 复述理解

在开始任务之前，或者发现问题之后，可以用这个 Prompt 让 AI 复述它的理解：

```markdown
在继续之前，请先回答以下问题：

1. **你理解的任务目标是什么？**
   （用一句话描述）

2. **你计划使用什么技术方案？**
   （列出关键技术点）

3. **有哪些地方你不确定，需要我澄清？**
   （如果没有就说"无"）

请先回答这些问题，确认理解一致后再开始写代码。
```

**为什么这招有效**：
- 提前暴露 AI 的误解
- 让你在写代码前就发现问题
- 比事后修改成本低得多

## 常见问题的快速定位

| 症状 | 最可能的原因 | 下一步 |
|-----|-------------|-------|
| 代码无法运行，报语法错误 | AI 生成了不完整的代码 | 让 AI 给出完整代码 |
| 运行时报 "undefined" | 缺少变量定义或异步问题 | 检查数据流，补充初始化 |
| 功能和描述不符 | AI 误解了需求 | 用更具体的语言重新描述 |
| 引入了不认识的库 | AI 过度发挥 | 明确约束，指定只用某些库 |
| 代码能跑但结果不对 | 逻辑幻觉 | 用边界测试验证，让 AI 自查 |
| 编译报类型错误 | API 幻觉或版本问题 | 查官方文档确认 API |
| 改了这里坏了那里 | 任务太大，上下文丢失 | 拆分任务，分步进行 |

## 本节要点

✓ **核心问题**：先判断是「我没说清楚」还是「AI 没做对」

✓ **三分钟诊断**：运行检查 → 依赖验证 → 测试运行，捕获 60% 问题

✓ **四象限分析**：根据任务复杂度 × 描述清晰度，选择不同策略

✓ **复述技巧**：让 AI 在动手前先说明理解，提前发现偏差

定位了问题之后，下一节我们来学习具体的修正策略——怎么让 AI 把代码改对。
