---
title: "12.3.5 é«˜çº§åº”ç”¨åœºæ™¯â€”â€”RAG ä¸å¤šæ¨¡æ€ï¼šæ£€ç´¢å¢å¼ºç”Ÿæˆä¸å›¾æ–‡æ··åˆ"
typora-root-url: ../../public
---

# 12.3.5 é«˜çº§åº”ç”¨åœºæ™¯â€”â€”RAG ä¸å¤šæ¨¡æ€ï¼šæ£€ç´¢å¢å¼ºç”Ÿæˆä¸å›¾æ–‡æ··åˆ

### ä¸€å¥è¯ç ´é¢˜

RAG è®© AI èƒ½"æŸ¥é˜…èµ„æ–™"åå›ç­”é—®é¢˜ï¼Œå¤šæ¨¡æ€è®© AI èƒ½"çœ‹å›¾è¯´è¯"â€”â€”è¿™ä¸¤é¡¹æŠ€æœ¯å¤§å¹…æ‰©å±•äº† AI åº”ç”¨çš„èƒ½åŠ›è¾¹ç•Œã€‚

### RAGï¼šæ£€ç´¢å¢å¼ºç”Ÿæˆ

#### ä»€ä¹ˆæ˜¯ RAGï¼Ÿ

```mermaid
graph LR
    A["ç”¨æˆ·æé—®"] --> B["æ£€ç´¢ç›¸å…³æ–‡æ¡£"]
    B --> C["å°†æ–‡æ¡£ä½œä¸ºä¸Šä¸‹æ–‡"]
    C --> D["AI åŸºäºä¸Šä¸‹æ–‡å›ç­”"]
    D --> E["è¿”å›ç­”æ¡ˆ"]
```

RAG çš„æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š**å…ˆæœç´¢ï¼Œå†å›ç­”**ã€‚è¿™è§£å†³äº† AI çŸ¥è¯†è¿‡æ—¶ã€æ— æ³•è®¿é—®ç§æœ‰æ•°æ®ç­‰é—®é¢˜ã€‚

#### åŸºç¡€å®ç°

```typescript
// app/api/chat/route.ts
import { openai } from '@ai-sdk/openai';
import { streamText } from 'ai';
import { searchDocuments } from '@/lib/search'; // ä½ çš„æœç´¢é€»è¾‘

export async function POST(req: Request) {
  const { messages } = await req.json();
  
  // è·å–ç”¨æˆ·æœ€æ–°é—®é¢˜
  const lastMessage = messages[messages.length - 1];
  
  // æ£€ç´¢ç›¸å…³æ–‡æ¡£
  const relevantDocs = await searchDocuments(lastMessage.content);
  
  // æ„å»ºä¸Šä¸‹æ–‡
  const context = relevantDocs
    .map((doc) => `---\n${doc.title}\n${doc.content}\n---`)
    .join('\n');

  const result = streamText({
    model: openai('gpt-4o'),
    system: `ä½ æ˜¯ä¸€ä¸ªçŸ¥è¯†åŠ©æ‰‹ã€‚è¯·æ ¹æ®ä»¥ä¸‹èµ„æ–™å›ç­”ç”¨æˆ·é—®é¢˜ã€‚å¦‚æœèµ„æ–™ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·è¯šå®åœ°è¯´ä¸çŸ¥é“ã€‚

å‚è€ƒèµ„æ–™ï¼š
${context}`,
    messages,
  });

  return result.toDataStreamResponse();
}
```

#### å‘é‡æœç´¢

æ›´é«˜çº§çš„ RAG å®ç°ä¼šä½¿ç”¨å‘é‡æ•°æ®åº“è¿›è¡Œè¯­ä¹‰æœç´¢ï¼š

```typescript
import { embed } from 'ai';
import { openai } from '@ai-sdk/openai';

// ç”Ÿæˆæ–‡æœ¬åµŒå…¥
async function getEmbedding(text: string) {
  const { embedding } = await embed({
    model: openai.embedding('text-embedding-3-small'),
    value: text,
  });
  return embedding;
}

// åœ¨å‘é‡æ•°æ®åº“ä¸­æœç´¢
async function semanticSearch(query: string) {
  const queryEmbedding = await getEmbedding(query);
  
  // ä½¿ç”¨ Pineconeã€Supabase Vector ç­‰è¿›è¡Œç›¸ä¼¼åº¦æœç´¢
  const results = await vectorDB.search(queryEmbedding, { topK: 5 });
  
  return results;
}
```

### å¤šæ¨¡æ€ï¼šå›¾æ–‡æ··åˆ

#### å‘é€å›¾ç‰‡ç»™ AI

```typescript
// app/api/vision/route.ts
import { openai } from '@ai-sdk/openai';
import { streamText } from 'ai';

export async function POST(req: Request) {
  const { messages } = await req.json();

  const result = streamText({
    model: openai('gpt-4o'), // æ”¯æŒè§†è§‰çš„æ¨¡å‹
    messages: messages.map((m) => ({
      role: m.role,
      content: m.image
        ? [
            { type: 'text', text: m.content },
            { type: 'image', image: m.image }, // base64 æˆ– URL
          ]
        : m.content,
    })),
  });

  return result.toDataStreamResponse();
}
```

#### å‰ç«¯ä¸Šä¼ å›¾ç‰‡

```tsx
'use client';

import { useChat } from 'ai/react';
import { useState } from 'react';

export default function VisionChat() {
  const { messages, append, isLoading } = useChat();
  const [input, setInput] = useState('');
  const [image, setImage] = useState<string | null>(null);

  const handleImageUpload = (e: React.ChangeEvent<HTMLInputElement>) => {
    const file = e.target.files?.[0];
    if (file) {
      const reader = new FileReader();
      reader.onloadend = () => {
        setImage(reader.result as string);
      };
      reader.readAsDataURL(file);
    }
  };

  const handleSubmit = () => {
    if (!input.trim() && !image) return;
    
    append({
      role: 'user',
      content: input,
      // æ‰©å±•å­—æ®µï¼Œéœ€è¦åœ¨ API ç«¯å¤„ç†
      data: { image },
    });
    
    setInput('');
    setImage(null);
  };

  return (
    <div>
      {/* æ¶ˆæ¯åˆ—è¡¨ */}
      
      <div className="flex gap-2 p-4">
        <input
          type="file"
          accept="image/*"
          onChange={handleImageUpload}
          className="hidden"
          id="image-upload"
        />
        <label htmlFor="image-upload" className="cursor-pointer">
          ğŸ“
        </label>
        
        {image && (
          <img src={image} alt="ä¸Šä¼ é¢„è§ˆ" className="w-16 h-16 object-cover rounded" />
        )}
        
        <input
          value={input}
          onChange={(e) => setInput(e.target.value)}
          placeholder="æè¿°è¿™å¼ å›¾ç‰‡..."
          className="flex-1 p-2 border rounded"
        />
        
        <button onClick={handleSubmit} disabled={isLoading}>
          å‘é€
        </button>
      </div>
    </div>
  );
}
```

### AI åä½œæŒ‡å—

- **æ ¸å¿ƒæ„å›¾**ï¼šè®© AI å¸®ä½ å®ç° RAG æˆ–å¤šæ¨¡æ€åŠŸèƒ½ã€‚
- **éœ€æ±‚å®šä¹‰å…¬å¼**ï¼š
  - RAGï¼š`"è¯·å¸®æˆ‘å®ç°ä¸€ä¸ªåŸºäºå‘é‡æœç´¢çš„ RAG ç³»ç»Ÿï¼Œä½¿ç”¨ Supabase ä½œä¸ºå‘é‡æ•°æ®åº“ï¼Œç”¨æˆ·å¯ä»¥ä¸Šä¼  PDF æ–‡æ¡£å¹¶è¿›è¡Œé—®ç­”ã€‚"`
  - å¤šæ¨¡æ€ï¼š`"è¯·å¸®æˆ‘å®ç°ä¸€ä¸ªæ”¯æŒå›¾ç‰‡ä¸Šä¼ çš„ AI èŠå¤©ç•Œé¢ï¼Œç”¨æˆ·å¯ä»¥ä¸Šä¼ å›¾ç‰‡å¹¶è¯¢é—®å›¾ç‰‡å†…å®¹ã€‚"`
- **å…³é”®æœ¯è¯­**ï¼š`RAG`ã€`embedding`ã€`å‘é‡æœç´¢`ã€`å¤šæ¨¡æ€ (multimodal)`ã€`vision`

### é¿å‘æŒ‡å—

- **RAG çš„æ£€ç´¢è´¨é‡å†³å®šå›ç­”è´¨é‡**ï¼šåƒåœ¾è¿›ï¼Œåƒåœ¾å‡ºã€‚
- **å›¾ç‰‡å¤§å°é™åˆ¶**ï¼šå¤§å›¾ç‰‡ä¼šæ¶ˆè€—å¤§é‡ Tokenï¼Œå»ºè®®å‹ç¼©åä¸Šä¼ ã€‚
- **å‘é‡æ•°æ®åº“é€‰æ‹©**ï¼šè€ƒè™‘æˆæœ¬ã€æ€§èƒ½å’Œæ˜“ç”¨æ€§çš„å¹³è¡¡ã€‚
- **ä¸Šä¸‹æ–‡çª—å£é™åˆ¶**ï¼šæ£€ç´¢çš„æ–‡æ¡£ä¸èƒ½å¤ªé•¿ï¼Œå¦åˆ™ä¼šè¶…å‡ºæ¨¡å‹é™åˆ¶ã€‚
